{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline comprimido - Proyecto 1 Etapa 2 G32\n",
    "El propósito de este archivo es crear el pipeline, con los fragmentos de código claves de la exploración en la etapa 1. De aquí se obtendrá el .joblib que se utilizará en el back."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c670881f5224f6e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Actualizaciones, instalaciones e importaciones"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff326bb74046c7b9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (69.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: jupyter in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 7)) (0.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 8)) (3.8.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.11.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 10)) (69.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 11)) (1.4.1.post1)\n",
      "Requirement already satisfied: ydata-profiling in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 12)) (4.7.0)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 13)) (3.1.2)\n",
      "Requirement already satisfied: PyQt5 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 14)) (5.15.10)\n",
      "Requirement already satisfied: inflect in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 17)) (7.2.0)\n",
      "Requirement already satisfied: contractions in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 18)) (0.1.73)\n",
      "Requirement already satisfied: scikit-plot in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 19)) (0.3.7)\n",
      "Requirement already satisfied: nltk in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 20)) (3.8.1)\n",
      "Requirement already satisfied: stanza in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 23)) (1.8.1)\n",
      "Requirement already satisfied: fastapi in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 26)) (0.110.1)\n",
      "Requirement already satisfied: pydantic in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 27)) (2.6.4)\n",
      "Requirement already satisfied: uvicorn in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from -r ../requirements.txt (line 28)) (0.29.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from pandas->-r ../requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from pandas->-r ../requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from pandas->-r ../requirements.txt (line 2)) (2024.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter->-r ../requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter->-r ../requirements.txt (line 6)) (5.5.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter->-r ../requirements.txt (line 6)) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter->-r ../requirements.txt (line 6)) (7.16.3)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter->-r ../requirements.txt (line 6)) (6.29.4)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter->-r ../requirements.txt (line 6)) (8.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from matplotlib->-r ../requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 11)) (3.4.0)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (6.0.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (3.1.3)\n",
      "Requirement already satisfied: visions<0.7.7,>=0.7.5 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->-r ../requirements.txt (line 12)) (0.7.6)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (0.12.4)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (4.66.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (1.11.2)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (0.14.1)\n",
      "Requirement already satisfied: typeguard<5,>=4.1.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (4.2.1)\n",
      "Requirement already satisfied: imagehash==4.3.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (1.9.3)\n",
      "Requirement already satisfied: dacite>=1.8 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (1.8.1)\n",
      "Requirement already satisfied: numba<1,>=0.56.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ydata-profiling->-r ../requirements.txt (line 12)) (0.59.1)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling->-r ../requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from openpyxl->-r ../requirements.txt (line 13)) (1.1.0)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.13 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from PyQt5->-r ../requirements.txt (line 14)) (12.13.0)\n",
      "Requirement already satisfied: PyQt5-Qt5>=5.15.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from PyQt5->-r ../requirements.txt (line 14)) (5.15.2)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from inflect->-r ../requirements.txt (line 17)) (10.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from inflect->-r ../requirements.txt (line 17)) (4.10.0)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from contractions->-r ../requirements.txt (line 18)) (0.0.24)\n",
      "Requirement already satisfied: click in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nltk->-r ../requirements.txt (line 20)) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nltk->-r ../requirements.txt (line 20)) (2023.12.25)\n",
      "Requirement already satisfied: emoji in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stanza->-r ../requirements.txt (line 23)) (2.11.0)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stanza->-r ../requirements.txt (line 23)) (5.26.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stanza->-r ../requirements.txt (line 23)) (3.2.1)\n",
      "Requirement already satisfied: toml in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stanza->-r ../requirements.txt (line 23)) (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stanza->-r ../requirements.txt (line 23)) (2.2.2)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from fastapi->-r ../requirements.txt (line 26)) (0.37.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 27)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from pydantic->-r ../requirements.txt (line 27)) (2.16.3)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from uvicorn->-r ../requirements.txt (line 28)) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from click->nltk->-r ../requirements.txt (line 20)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->-r ../requirements.txt (line 12)) (2.1.5)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from numba<1,>=0.56.0->ydata-profiling->-r ../requirements.txt (line 12)) (0.42.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r ../requirements.txt (line 2)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->-r ../requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->-r ../requirements.txt (line 12)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->-r ../requirements.txt (line 12)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->-r ../requirements.txt (line 12)) (2024.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from starlette<0.38.0,>=0.37.2->fastapi->-r ../requirements.txt (line 26)) (4.3.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from statsmodels<1,>=0.13.2->ydata-profiling->-r ../requirements.txt (line 12)) (0.5.6)\n",
      "Requirement already satisfied: anyascii in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from textsearch>=0.0.21->contractions->-r ../requirements.txt (line 18)) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from textsearch>=0.0.21->contractions->-r ../requirements.txt (line 18)) (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from torch>=1.3.0->stanza->-r ../requirements.txt (line 23)) (3.13.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from torch>=1.3.0->stanza->-r ../requirements.txt (line 23)) (1.12)\n",
      "Requirement already satisfied: fsspec in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from torch>=1.3.0->stanza->-r ../requirements.txt (line 23)) (2024.3.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling->-r ../requirements.txt (line 12)) (23.2.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (8.23.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (5.9.8)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipykernel->jupyter->-r ../requirements.txt (line 6)) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipywidgets->jupyter->-r ../requirements.txt (line 6)) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipywidgets->jupyter->-r ../requirements.txt (line 6)) (3.0.10)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-console->jupyter->-r ../requirements.txt (line 6)) (3.0.43)\n",
      "Requirement already satisfied: pygments in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-console->jupyter->-r ../requirements.txt (line 6)) (2.17.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (5.10.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbconvert->jupyter->-r ../requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from notebook->jupyter->-r ../requirements.txt (line 6)) (2.13.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from notebook->jupyter->-r ../requirements.txt (line 6)) (2.25.4)\n",
      "Requirement already satisfied: jupyterlab<4.2,>=4.1.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from notebook->jupyter->-r ../requirements.txt (line 6)) (4.1.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from notebook->jupyter->-r ../requirements.txt (line 6)) (0.2.4)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from qtconsole->jupyter->-r ../requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi->-r ../requirements.txt (line 26)) (1.3.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter->-r ../requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (0.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r ../requirements.txt (line 6)) (4.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter->-r ../requirements.txt (line 6)) (306)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (0.5.3)\n",
      "Requirement already satisfied: overrides in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (0.20.0)\n",
      "Requirement already satisfied: pywinpty in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (2.0.13)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.7.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r ../requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r ../requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r ../requirements.txt (line 6)) (2.2.4)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r ../requirements.txt (line 6)) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r ../requirements.txt (line 6)) (0.9.24)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r ../requirements.txt (line 6)) (4.21.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter->-r ../requirements.txt (line 6)) (2.19.1)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter->-r ../requirements.txt (line 6)) (0.2.13)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter->-r ../requirements.txt (line 6)) (2.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from sympy->torch>=1.3.0->stanza->-r ../requirements.txt (line 23)) (1.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.2,>=4.1.1->notebook->jupyter->-r ../requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r ../requirements.txt (line 6)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r ../requirements.txt (line 6)) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter->-r ../requirements.txt (line 6)) (0.18.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (0.1.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (21.2.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r ../requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: fqdn in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (2.4)\n",
      "Requirement already satisfied: uri-template in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (2.22)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\alvar\\prog\\bi\\isis-3301-p1-g32\\env\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter->-r ../requirements.txt (line 6)) (2.9.0.20240316)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\alvar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "!python -m pip install --upgrade pip\n",
    "!pip install --upgrade setuptools\n",
    "!pip install -r ../requirements.txt\n",
    "\n",
    "# Instalación de librerias\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import stanza\n",
    "from copy import deepcopy\n",
    "from math import floor\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.846410400Z",
     "start_time": "2024-04-20T00:45:04.947770Z"
    }
   },
   "id": "91040a8a47bb3b9a",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lectura y preparación de datos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "338bf4f6a0a8437e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/raw/tipo2_entrenamiento_estudiantes.csv', sep=',', encoding = 'utf-8')\n",
    "# Asignación a una nueva variable de los datos leidos\n",
    "data_t=deepcopy(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.910795500Z",
     "start_time": "2024-04-20T00:45:15.843402800Z"
    }
   },
   "id": "46515fd66602f163",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def atypical_length(df, alfa, beta):\n",
    "    \"\"\"\n",
    "    Elimina las reseñas con un bajo número de palabras dado que no son dicientes\n",
    "    \n",
    "    :param df: (DataFrame) reseñas y califiaciones de los usuarios\n",
    "    :param alfa: (float) porcentaje en cola izquierda excluido\n",
    "    :param alfa: (float) porcentaje en cola derecha excluido\n",
    "    :return: (DataFrame) elimina las entradas con menos palabras que el umbral dado\n",
    "    \"\"\"\n",
    "    \n",
    "    df_longitudes = df.copy()\n",
    "    df_longitudes['Conteo'] = [len(x.split()) for x in df_longitudes['Review']]\n",
    "    \n",
    "    upper = df_longitudes['Conteo'].quantile(1-beta)\n",
    "    lower = df_longitudes['Conteo'].quantile(alfa)\n",
    "    \n",
    "    chosen = df_longitudes[df_longitudes['Conteo'] > lower]\n",
    "    chosen = chosen[chosen['Conteo'] < upper]\n",
    "    \n",
    "    #print(\"Mínimo número palabras: \", min(chosen['Conteo']))\n",
    "    #print(\"Máximo número palabras: \", max(chosen['Conteo']))\n",
    "    \n",
    "    chosen = chosen.drop(columns=['Conteo'])\n",
    "    \n",
    "    return chosen\n",
    "\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    \"\"\"\n",
    "    Elimina las reseñas duplicadas en la columna Review\n",
    "    \n",
    "    :param df: dataframe a manipular\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    return df.drop_duplicates()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.912013800Z",
     "start_time": "2024-04-20T00:45:15.889400600Z"
    }
   },
   "id": "96138d9c4d1c7e49",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entrenamientos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1164c73340340c2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_processed_data(file_name, frac=1):\n",
    "    \"\"\"\n",
    "    Carga el archivo de datos procesados y los\n",
    "    procesa para el entrenamiento\n",
    "    \n",
    "    :param file_name: nombre del archivo a cargar. Debe ser .csv, pero no se pasa la extensión\n",
    "    :param frac: tamaño del dataset que se carga como porcentaje entre 0.00 y 1.00\n",
    "    :return: train set y test set separados en features y objetivo\n",
    "    \"\"\"\n",
    "    \n",
    "    data_p=pd.read_csv('../data/processed/' + file_name + '.csv', sep=';', encoding = 'utf-8')\n",
    "    # Asignación a una nueva variable de los datos leidos\n",
    "    data_p = data_p.sample(n=floor(frac*data_p.shape[0]))\n",
    "    print(\"Número de datos encontrados:\", data_p.shape)\n",
    "    \n",
    "    return data_p\n",
    "    \n",
    "    \n",
    "def separate_data(data_p, test_size):\n",
    "    \"\"\"\n",
    "    Separa el dataframe en train y test sets\n",
    "    \n",
    "    :param data: dataframe cargado\n",
    "    :param test_size: tamaño de los tests sets en comparación con los datos totales\n",
    "    :return: xtr, xts, ytr, yts\n",
    "    \"\"\"\n",
    "    x = data_p.iloc[:,:-1]\n",
    "    y = data_p.iloc[:,-1]\n",
    "    \n",
    "    xtr, xts, ytr, yts = train_test_split(x, y, test_size=test_size, random_state=42069)\n",
    "    \n",
    "    print(\"X train set:\", xtr.shape)\n",
    "    print(\"X test  set:\", xts.shape)\n",
    "    print(\"Y train set:\", ytr.shape)\n",
    "    print(\"Y test  set:\", yts.shape)\n",
    "    \n",
    "    return xtr, xts, ytr, yts\n",
    "\n",
    "\n",
    "def custom_sampling(df, objective_distribution):\n",
    "    \"\"\"\n",
    "    Hace un muestreo personalizado de las cinco clases. \n",
    "    Las que estén subrepresentadas se sobremuestruean y las\n",
    "    que estén sobre representadas se submuestrean\n",
    "    \n",
    "    :param df: dataframe de datos procesados\n",
    "    :return: dataframe con distribución uniforme\n",
    "    \"\"\"\n",
    "    total_count = df.shape[0]\n",
    "    \n",
    "    for cls, per in objective_distribution.items():\n",
    "        class_df = df[df['Class'] == cls]\n",
    "        desired_count = int(total_count * per)\n",
    "        \n",
    "        resample_df = class_df.sample(desired_count, replace=True)\n",
    "        # Combine with the existing DataFrame\n",
    "        df = pd.concat([df[df['Class'] != cls], resample_df], ignore_index=True)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "def uniform_sampling(df):\n",
    "    \"\"\"\n",
    "    Hace un muestreo uniforme de las cinco clases. \n",
    "    Las que estén subrepresentadas se sobremuestruean y las\n",
    "    que estén sobrerepresentadas se submuestrean\n",
    "    :param df: dataframe de datos procesados\n",
    "    :return: dataframe con distribución uniforme\n",
    "    \"\"\"\n",
    "    # Undersampled classes and oversampled classes\n",
    "    \n",
    "    # Sample under-represented classes to reach a desired count (adjust count as needed)\n",
    "    desired_count = df.shape[0]//5  # Match the count of correctly sampled class\n",
    "    \n",
    "    objective_values = set(df['Class'].to_list())\n",
    "    objective_distribution = dict\n",
    "    \n",
    "    for v in objective_values:\n",
    "        objective_distribution[v] = 1//len(objective_values)\n",
    "    \n",
    "    return custom_sampling(df, objective_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.925531900Z",
     "start_time": "2024-04-20T00:45:15.895901600Z"
    }
   },
   "id": "c4e655ff341db9d1",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_nb(xtr, xts, ytr, yts, nbchoice):\n",
    "    \"\"\"\n",
    "    Entrena un Bayes Ingenuo dado\n",
    "    \n",
    "    :param xtr: features de entrenamiento\n",
    "    :param xts: features de test\n",
    "    :param ytr: var. objetivo de entrenamiento\n",
    "    :param yts: var. objetivo de test\n",
    "    :param nbchoice: modelo de Bayes Ingenuo elegido\n",
    "    :return: el modelo Bayes Ingenuo entrenado\n",
    "    \"\"\"\n",
    "    nb = nbchoice()\n",
    "    \n",
    "    # entrena el modelo\n",
    "    nb.fit(xtr, ytr)\n",
    "    \n",
    "    # predice para el test set\n",
    "    ypred = nb.predict(xts)\n",
    "    \n",
    "    print(classification_report(yts, ypred, target_names=['1','2','3','4','5']))\n",
    "    \n",
    "    return nb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.929007800Z",
     "start_time": "2024-04-20T00:45:15.907890300Z"
    }
   },
   "id": "677fda4087707664",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "objective_distribution = {\n",
    "        1 : 0.170,\n",
    "        2 : 0.170,\n",
    "        3 : 0.235,\n",
    "        4 : 0.240,\n",
    "        5 : 0.205\n",
    "    }\n",
    "# df = custom_sampling(dt_vectorized, objective_distribution)\n",
    "# xtr, xts, ytr, yts = separate_data(df, 0.20)\n",
    "# mnb = train_nb(xtr, xts, ytr, yts, MultinomialNB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.975418100Z",
     "start_time": "2024-04-20T00:45:15.912013800Z"
    }
   },
   "id": "497b78e7e593d00f",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# gnb = train_nb(xtr, xts, ytr, yts, GaussianNB)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.976428Z",
     "start_time": "2024-04-20T00:45:15.916634600Z"
    }
   },
   "id": "2a0a299971beabea",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# \n",
    "# def trainSVM(xtr, xts, ytr, yts):\n",
    "#     \"\"\"\n",
    "#     Entrena un modelo con SVM y lo prueba, sin usar pipeline.\n",
    "# \n",
    "#     :param xtr: features de entrenamiento\n",
    "#     :param xts: features de test\n",
    "#     :param ytr: var. objetivo de entrenamiento\n",
    "#     :param yts: var. objetivo de test\n",
    "#     :return: el modelo de SVM entrenado\n",
    "#     \"\"\"\n",
    "# \n",
    "#     svm = SVC(random_state=0)\n",
    "#     param_grid = {\n",
    "#         'C': [0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "#         'kernel': ['linear', 'rbf'],  # Linear y RBF son los kernels más comunes\n",
    "#     }\n",
    "#     grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "#     grid_search.fit(xtr, ytr)\n",
    "#     best_params = grid_search.best_params_\n",
    "#     print(\"Mejores parámetros:\", best_params)\n",
    "#     # Crear y entrenar el modelo con los mejores parámetros encontrados\n",
    "#     best_model = SVC(**best_params, random_state=0)\n",
    "#     best_model.fit(xtr, ytr)\n",
    "# \n",
    "#     # Predecir con el conjunto de test escalado\n",
    "#     ypred = best_model.predict(xts)\n",
    "#     print(classification_report(yts, ypred, target_names=['1', '2', '3', '4', '5']))\n",
    "#     cm = confusion_matrix(yts, ypred, labels=[1, 2, 3, 4, 5])\n",
    "#     disp = ConfusionMatrixDisplay(cm, display_labels=[1,2,3,4,5])\n",
    "#     \n",
    "#     # Plot the confusion matrix with colors\n",
    "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#     disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "#     \n",
    "#     # Add a colorbar\n",
    "#     plt.colorbar(disp.im_, ax=ax)\n",
    "#     \n",
    "#     # Add title and labels\n",
    "#     ax.set_title('Confusion Matrix with Colors')\n",
    "#     ax.set_xlabel('Predicted Labels')\n",
    "#     ax.set_ylabel('True Labels')\n",
    "#     \n",
    "#     # Show the plot\n",
    "#     plt.show()\n",
    "#     \n",
    "#     return best_model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.977657100Z",
     "start_time": "2024-04-20T00:45:15.921614400Z"
    }
   },
   "id": "d9a595a22a9eef9c",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# objective_distribution = {\n",
    "#         1 : 0.201,\n",
    "#         2 : 0.201,\n",
    "#         3 : 0.180,\n",
    "#         4 : 0.194,\n",
    "#         5 : 0.190\n",
    "#     }\n",
    "# \n",
    "# df = custom_sampling(dt_vectorized, objective_distribution)\n",
    "# xtr, xts, ytr, yts = separate_data(df, 0.20)\n",
    "# svm_model = trainSVM(xtr, xts, ytr, yts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.991875600Z",
     "start_time": "2024-04-20T00:45:15.926540Z"
    }
   },
   "id": "ab0b9e6d51ac0b5",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Forma Pipeline"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc6a16c3efb66023"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class Preprocessing(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, vocabulary=None):\n",
    "        if vocabulary is not None:\n",
    "            print(\"Vocabulary given\")\n",
    "            self.feature_vectorizer_algorithm = TfidfVectorizer (\n",
    "                decode_error='ignore',\n",
    "                strip_accents='ascii',\n",
    "                analyzer='word',\n",
    "                vocabulary=vocabulary\n",
    "            )\n",
    "        else:\n",
    "            print(\"Generating new vocabulary\")\n",
    "            self.feature_vectorizer_algorithm = TfidfVectorizer (\n",
    "                decode_error='ignore',\n",
    "                strip_accents='ascii',\n",
    "                analyzer='word',\n",
    "                max_features=10000\n",
    "            )\n",
    "            \n",
    "        print(\"Inicializando preprocessing...\")\n",
    "        # algoritmo de vectorización de features\n",
    "        \n",
    "        # features\n",
    "        self.feature_names = None\n",
    "        # stanza pipeline\n",
    "        self.stanza_pipeline = stanza.Pipeline(lang=\"es\", processors=\"tokenize,mwt,pos,lemma\")\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def stanza_preprocessing(self, words):\n",
    "        \"\"\"\n",
    "        Uses the Stanza Pipeline to preprocess text\n",
    "        Recommended before cleaning as stopword eliminations, lower-casing\n",
    "        and punctuation removal affect POS and word tagging for lemma resolution\n",
    "        \n",
    "        :param words: (list) unclean words passed through the pipeline\n",
    "        :param pipe: (stanza.Pipeline) stanza Pipeline used\n",
    "        :return: (list) lemmas obtained\n",
    "        \"\"\"\n",
    "        doc = self.stanza_pipeline(words)\n",
    "        lemmas = [w.lemma for w in doc.sentences[0].words]\n",
    "        return lemmas\n",
    "        \n",
    "    \n",
    "    def remove_non_ascii(self, words):\n",
    "        \"\"\"\n",
    "        Remueve caractéres no ASCII de la lista de palabras tokenizadas\n",
    "        \n",
    "        :param words: (list) lista de palabras tokenizadas\n",
    "        :returns: (list) lista de palabras/strings 'ASCII-zadas'\n",
    "        \"\"\"\n",
    "        # TODO: reconsiderar entre ASCII y UTF-8\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word is not None:\n",
    "                # debe ser codificado en UTF-8 para no obstaculizar al lematizador\n",
    "              new_word = unicodedata.normalize('NFKD', word).encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "              new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def to_lowercase(self, words):\n",
    "        \"\"\"\n",
    "        Convierte todos los caracteres a minúscula de la lista de palabras tokenizadas\n",
    "        \n",
    "        :param words: (list) lista de palabras tokenizadas\n",
    "        :returns: (list) lista de palabras en minúscula\n",
    "        \"\"\"\n",
    "        return [w.lower() for w in words]\n",
    "    \n",
    "    \n",
    "    def remove_punctuation(self, words):\n",
    "        \"\"\"\n",
    "        Remove punctuation from list of tokenized words\n",
    "        \n",
    "        :param words: (list) lista de palabas\n",
    "        :returns: (list) lista de palabras con puntuación removida\n",
    "        \"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word is not None:\n",
    "                new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "                if new_word != '':\n",
    "                    new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def replace_numbers(self, words):\n",
    "       \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "       p = inflect.engine()\n",
    "       print(words)\n",
    "       new_words = []\n",
    "       for word in words:\n",
    "           if word.isdigit():\n",
    "               new_word = p.number_to_words(word)\n",
    "               new_words.append(new_word)\n",
    "               print(\"if \" + new_word)\n",
    "           else:\n",
    "               new_words.append(word)\n",
    "       return new_words\n",
    "    \n",
    "    \n",
    "    def remove_stopwords(self, words):\n",
    "        \"\"\"\n",
    "        Remueve las stop words de la lista de palabras tokenizadas\n",
    "        \n",
    "        :param words: (list) lista de palabras tokenizadas\n",
    "        :returns: (list) lista de palabras sin stop words\n",
    "        \"\"\"\n",
    "        \n",
    "        languages = ['spanish']\n",
    "        stopword = nltk.corpus.stopwords.words(languages)\n",
    "        \n",
    "        # in case of only spanish, contractions are included as stopwords\n",
    "        return [w for w in words if w not in stopword]\n",
    "        \n",
    "        \n",
    "    def separate_contractions(self, words):\n",
    "        \"\"\"\n",
    "        Elimina las contracciones. Cubre inglés, las contracciones en español están cubiertas\n",
    "        con las stopwords\n",
    "        \n",
    "        :param words: lista de palabras tokenizadas\n",
    "        :return: lista de palabras sin contracciones\n",
    "        \"\"\"\n",
    "        return words.apply(contractions.fix)\n",
    "    \n",
    "    \n",
    "    # se renombra el preprocessing como cleaning\n",
    "    def cleaning(self, words):\n",
    "        words = self.to_lowercase(words)\n",
    "    #    words = self.replace_numbers(words)\n",
    "        words = self.remove_punctuation(words)\n",
    "        words = self.remove_non_ascii(words)\n",
    "        words = self.remove_stopwords(words)\n",
    "    #    words = self.separate_contractions(words)\n",
    "        return words\n",
    "    \n",
    "    \n",
    "    def vectorize(self, X):\n",
    "        \"\"\"\n",
    "        Vectoriza las features utilizando el algoritmo provisto\n",
    "        \n",
    "        :param data: data frame de datos procesados\n",
    "        :param feature_vectorizer_algorithm: algoritmo de vectorización a utilizar para features\n",
    "        :return: (lista de números correspondientes a la vectorización, arreglo de features)\n",
    "        \"\"\"\n",
    "        X['Review'] = X['Review'].apply(lambda x: ' '.join(map(str, x)))\n",
    "        \n",
    "        x_data = X['Review']\n",
    "        \n",
    "        x_data_vectorized_matrix = self.feature_vectorizer_algorithm.fit_transform(x_data)\n",
    "        x_data_vectorized_df = pd.DataFrame(x_data_vectorized_matrix.toarray())  # ... for additional features from csr_matrix\n",
    "        \n",
    "        # obtiene el arreglo de palabras con columnas\n",
    "        self.feature_names = self.feature_vectorizer_algorithm.get_feature_names_out()\n",
    "        \n",
    "        res = pd.concat([x_data_vectorized_df], axis=1)\n",
    "        \n",
    "        return res\n",
    "\n",
    "    \n",
    "    def transform(self, X):        \n",
    "        # tokenización + lematización Stanza\n",
    "        print(\"Stanza preprocessing... \", end=\"\")\n",
    "        X['Review'] = X['Review'].apply(self.stanza_preprocessing)\n",
    "        print(\"OK\", X.shape)\n",
    "        \n",
    "        # limpieza\n",
    "        print(\"Additional cleaning... \", end=\"\")\n",
    "        X['Review'] = X['Review'].apply(self.cleaning)\n",
    "        print(\"OK\", X.shape)\n",
    "        \n",
    "        # vectorización de features\n",
    "        print(\"Feature and objective vectorization... \", end=\"\")\n",
    "        # se guarda de esta manera para no afectar el pipeline. Se podría analizar una manera más ortodoxa de hacer\n",
    "        X = self.vectorize(X)\n",
    "        \n",
    "        # pueden quedar columnas libres por eliminación de stopwords. Se llenan con 0s\n",
    "        X = X.fillna(0)\n",
    "        # valores en clase se vuelven floats, toca retornar a int\n",
    "        # X['Class'] = X['Class'].apply(lambda x: int(x) if pd.notnull(x) else x)\n",
    "        # # valores de 0 en clase son erróneos\n",
    "        # X = X[X['Class'] != 0]\n",
    "        \n",
    "        print(\"OK\", X.shape)\n",
    "        \n",
    "        return X\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.993876800Z",
     "start_time": "2024-04-20T00:45:15.932366200Z"
    }
   },
   "id": "df82f0e0b33ff48e",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Process(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):        \n",
    "        # features\n",
    "        self.feature_names = None\n",
    "        # stanza pipeline\n",
    "        self.stanza_pipeline = stanza.Pipeline(lang=\"es\", processors=\"tokenize,mwt,pos,lemma\")\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def stanza_preprocessing(self, words):\n",
    "        \"\"\"\n",
    "        Uses the Stanza Pipeline to preprocess text\n",
    "        Recommended before cleaning as stopword eliminations, lower-casing\n",
    "        and punctuation removal affect POS and word tagging for lemma resolution\n",
    "        \n",
    "        :param words: (list) unclean words passed through the pipeline\n",
    "        :param pipe: (stanza.Pipeline) stanza Pipeline used\n",
    "        :return: (list) lemmas obtained\n",
    "        \"\"\"\n",
    "        doc = self.stanza_pipeline(words)\n",
    "        lemmas = [w.lemma for w in doc.sentences[0].words]\n",
    "        return lemmas\n",
    "        \n",
    "    \n",
    "    def remove_non_ascii(self, words):\n",
    "        \"\"\"\n",
    "        Remueve caractéres no ASCII de la lista de palabras tokenizadas\n",
    "        \n",
    "        :param words: (list) lista de palabras tokenizadas\n",
    "        :returns: (list) lista de palabras/strings 'ASCII-zadas'\n",
    "        \"\"\"\n",
    "        # TODO: reconsiderar entre ASCII y UTF-8\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word is not None:\n",
    "                # debe ser codificado en UTF-8 para no obstaculizar al lematizador\n",
    "              new_word = unicodedata.normalize('NFKD', word).encode('utf-8', 'ignore').decode('utf-8', 'ignore')\n",
    "              new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def to_lowercase(self, words):\n",
    "        \"\"\"\n",
    "        Convierte todos los caracteres a minúscula de la lista de palabras tokenizadas\n",
    "        \n",
    "        :param words: (list) lista de palabras tokenizadas\n",
    "        :returns: (list) lista de palabras en minúscula\n",
    "        \"\"\"\n",
    "        return [w.lower() for w in words]\n",
    "    \n",
    "    \n",
    "    def remove_punctuation(self, words):\n",
    "        \"\"\"\n",
    "        Remove punctuation from list of tokenized words\n",
    "        \n",
    "        :param words: (list) lista de palabas\n",
    "        :returns: (list) lista de palabras con puntuación removida\n",
    "        \"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            if word is not None:\n",
    "                new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "                if new_word != '':\n",
    "                    new_words.append(new_word)\n",
    "        return new_words\n",
    "    \n",
    "    \n",
    "    def replace_numbers(self, words):\n",
    "       \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "       p = inflect.engine()\n",
    "       print(words)\n",
    "       new_words = []\n",
    "       for word in words:\n",
    "           if word.isdigit():\n",
    "               new_word = p.number_to_words(word)\n",
    "               new_words.append(new_word)\n",
    "               print(\"if \" + new_word)\n",
    "           else:\n",
    "               new_words.append(word)\n",
    "       return new_words\n",
    "    \n",
    "    \n",
    "    def remove_stopwords(self, words):\n",
    "        \"\"\"\n",
    "        Remueve las stop words de la lista de palabras tokenizadas\n",
    "        \n",
    "        :param words: (list) lista de palabras tokenizadas\n",
    "        :returns: (list) lista de palabras sin stop words\n",
    "        \"\"\"\n",
    "        \n",
    "        languages = ['spanish']\n",
    "        stopword = nltk.corpus.stopwords.words(languages)\n",
    "        \n",
    "        # in case of only spanish, contractions are included as stopwords\n",
    "        return [w for w in words if w not in stopword]\n",
    "        \n",
    "        \n",
    "    def separate_contractions(self, words):\n",
    "        \"\"\"\n",
    "        Elimina las contracciones. Cubre inglés, las contracciones en español están cubiertas\n",
    "        con las stopwords\n",
    "        \n",
    "        :param words: lista de palabras tokenizadas\n",
    "        :return: lista de palabras sin contracciones\n",
    "        \"\"\"\n",
    "        return words.apply(contractions.fix)\n",
    "    \n",
    "    \n",
    "    # se renombra el preprocessing como cleaning\n",
    "    def cleaning(self, words):\n",
    "        words = self.to_lowercase(words)\n",
    "    #    words = self.replace_numbers(words)\n",
    "        words = self.remove_punctuation(words)\n",
    "        words = self.remove_non_ascii(words)\n",
    "        words = self.remove_stopwords(words)\n",
    "    #    words = self.separate_contractions(words)\n",
    "        return words\n",
    "\n",
    "    \n",
    "    def transform(self, X):        \n",
    "        # tokenización + lematización Stanza\n",
    "        print(\"Stanza preprocessing... \", end=\"\")\n",
    "        X['Review'] = X['Review'].apply(self.stanza_preprocessing)\n",
    "        print(\"OK\", X.shape)\n",
    "        \n",
    "        # limpieza\n",
    "        print(\"Additional cleaning... \", end=\"\")\n",
    "        X['Review'] = X['Review'].apply(self.cleaning)\n",
    "        \n",
    "        print(\"OK\", X.shape)\n",
    "        \n",
    "        return X\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.994876300Z",
     "start_time": "2024-04-20T00:45:15.959103800Z"
    }
   },
   "id": "d217a3ee854a4c4c",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def training_preprocessing(data):\n",
    "    alfa = 0.05\n",
    "    beta = 0.05\n",
    "    \n",
    "    df = deepcopy(data)\n",
    "    \n",
    "    # eliminación de nulos\n",
    "    print(\"Null elimination... \", end=\"\")\n",
    "    df = df.dropna()\n",
    "    print(\"OK\", df.shape)\n",
    "    \n",
    "    # eliminación de duplicados\n",
    "    print(\"Duplicate elimination... \", end=\"\")\n",
    "    df = remove_duplicates(df)\n",
    "    print(\"OK\", df.shape)\n",
    "    \n",
    "    # eliminación de longitudes atípicas\n",
    "    print(\"Ayptical length elimination... \", end=\"\")\n",
    "    df = atypical_length(df, alfa, beta)\n",
    "    print(\"OK\", df.shape)\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.996876Z",
     "start_time": "2024-04-20T00:45:15.964237600Z"
    }
   },
   "id": "c994b1388c940beb",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SVM(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Entrena un modelo con SVM y lo prueba, sin usar pipeline.\n",
    "    \n",
    "        :param xtr: features de entrenamiento\n",
    "        :param xts: features de test\n",
    "        :param ytr: var. objetivo de entrenamiento\n",
    "        :param yts: var. objetivo de test\n",
    "        :return: el modelo de SVM entrenado\n",
    "        \"\"\"\n",
    "    \n",
    "        self.svm = SVC(random_state=0)\n",
    "        self.param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "            'kernel': ['linear', 'rbf'],  # Linear y RBF son los kernels más comunes\n",
    "        }\n",
    "        self.cv = 5\n",
    "        self.scoring = 'accuracy'\n",
    "        \n",
    "    # def fit(self, X):\n",
    "    #     grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "    #     grid_search.fit(xtr, ytr)\n",
    "    #     best_params = grid_search.best_params_\n",
    "    #     print(\"Mejores parámetros:\", best_params)\n",
    "    #     # Crear y entrenar el modelo con los mejores parámetros encontrados\n",
    "    #     best_model = SVC(**best_params, random_state=0)\n",
    "    #     best_model.fit(xtr, ytr)\n",
    "    # \n",
    "    #     # Predecir con el conjunto de test escalado\n",
    "    #     ypred = best_model.predict(xts)\n",
    "    #     print(classification_report(yts, ypred, target_names=['1', '2', '3', '4', '5']))\n",
    "    #     cm = confusion_matrix(yts, ypred, labels=[1, 2, 3, 4, 5])\n",
    "    #     disp = ConfusionMatrixDisplay(cm, display_labels=[1,2,3,4,5])\n",
    "    #     \n",
    "    #     # Plot the confusion matrix with colors\n",
    "    #     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    #     disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "    #     \n",
    "    #     # Add a colorbar\n",
    "    #     plt.colorbar(disp.im_, ax=ax)\n",
    "    #     \n",
    "    #     # Add title and labels\n",
    "    #     ax.set_title('Confusion Matrix with Colors')\n",
    "    #     ax.set_xlabel('Predicted Labels')\n",
    "    #     ax.set_ylabel('True Labels')\n",
    "    #     \n",
    "    #     # Show the plot\n",
    "    #     plt.show()\n",
    "    #     \n",
    "    #     return best_model\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:15.999875800Z",
     "start_time": "2024-04-20T00:45:15.971578900Z"
    }
   },
   "id": "65082c95a5d11915",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:45:15 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new vocabulary\n",
      "Inicializando preprocessing...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f474b0285bad4709a552e0c467c67ac7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:45:16 INFO: Downloaded file to C:\\Users\\alvar\\stanza_resources\\resources.json\n",
      "2024-04-19 19:45:16 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | ancora          |\n",
      "| mwt       | ancora          |\n",
      "| pos       | ancora_charlm   |\n",
      "| lemma     | ancora_nocharlm |\n",
      "===============================\n",
      "\n",
      "2024-04-19 19:45:16 INFO: Using device: cpu\n",
      "2024-04-19 19:45:16 INFO: Loading: tokenize\n",
      "2024-04-19 19:45:18 INFO: Loading: mwt\n",
      "2024-04-19 19:45:18 INFO: Loading: pos\n",
      "2024-04-19 19:45:19 INFO: Loading: lemma\n",
      "2024-04-19 19:45:19 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from joblib import parallel_backend\n",
    "\n",
    "svc_param_grid={\n",
    "    'C': [0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "    'kernel': ['linear', 'rbf'],  # Linear y RBF son los kernels más comunes\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('preprocessing', Preprocessing()),\n",
    "    ('classifier', GridSearchCV(SVC(), param_grid=svc_param_grid, cv=5, scoring='accuracy', n_jobs=None, verbose=2))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:19.268927200Z",
     "start_time": "2024-04-20T00:45:15.977657100Z"
    }
   },
   "id": "e1c3db9c658ffc6e",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(7802, 2)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/tipo2_entrenamiento_estudiantes.csv', sep=',', encoding = 'utf-8')\n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:19.356317600Z",
     "start_time": "2024-04-20T00:45:19.268927200Z"
    }
   },
   "id": "ca43aeb79ce28b2a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null elimination... OK (394, 2)\n",
      "Duplicate elimination... OK (394, 2)\n",
      "Ayptical length elimination... OK (353, 2)\n",
      "X train set: (282, 1)\n",
      "X test  set: (71, 1)\n",
      "Y train set: (282,)\n",
      "Y test  set: (71,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/tipo2_entrenamiento_estudiantes.csv', sep=',', encoding = 'utf-8')\n",
    "\n",
    "objective_distribution = {\n",
    "        1 : 0.201,\n",
    "        2 : 0.201,\n",
    "        3 : 0.180,\n",
    "        4 : 0.194,\n",
    "        5 : 0.190\n",
    "}\n",
    "# aún funciona, pero no sabemos si deberíamos usar todo el dataset\n",
    "#df_sampled = custom_sampling(df, objective_distribution)\n",
    "df_sampled = df.sample(frac=0.05)\n",
    "df_pp = training_preprocessing(df_sampled)\n",
    "\n",
    "xtr, xts, ytr, yts = separate_data(df_pp, 0.20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:19.432664100Z",
     "start_time": "2024-04-20T00:45:19.356317600Z"
    }
   },
   "id": "e4e1481505eb9f3",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:45:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary given\n",
      "Inicializando preprocessing...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "099426f45db14eabbe2c9aaa92184adf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:45:19 INFO: Downloaded file to C:\\Users\\alvar\\stanza_resources\\resources.json\n",
      "2024-04-19 19:45:20 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | ancora          |\n",
      "| mwt       | ancora          |\n",
      "| pos       | ancora_charlm   |\n",
      "| lemma     | ancora_nocharlm |\n",
      "===============================\n",
      "\n",
      "2024-04-19 19:45:20 INFO: Using device: cpu\n",
      "2024-04-19 19:45:20 INFO: Loading: tokenize\n",
      "2024-04-19 19:45:20 INFO: Loading: mwt\n",
      "2024-04-19 19:45:20 INFO: Loading: pos\n",
      "2024-04-19 19:45:20 INFO: Loading: lemma\n",
      "2024-04-19 19:45:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "pp = Preprocessing(vocabulary=['hola'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:20.986028200Z",
     "start_time": "2024-04-20T00:45:19.430662600Z"
    }
   },
   "id": "ad2783037dc23ca0",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 1)\n",
      "(282,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(xtr.shape)\n",
    "print(ytr.shape)\n",
    "print(type(xtr))\n",
    "print(type(ytr))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.006484800Z",
     "start_time": "2024-04-20T00:45:20.984728800Z"
    }
   },
   "id": "6dd087e3b8732bd6",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pipeline.fit(xtr, ytr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.008403600Z",
     "start_time": "2024-04-20T00:45:20.989871900Z"
    }
   },
   "id": "db66f926793b896c",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print(xts.shape)\n",
    "# print(yts.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.021150500Z",
     "start_time": "2024-04-20T00:45:20.995941100Z"
    }
   },
   "id": "4602c037c75a1377",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pipeline.score(xts, yts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.027474800Z",
     "start_time": "2024-04-20T00:45:21.000809800Z"
    }
   },
   "id": "dd0e557349117456",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# features = pipeline[0].feature_vectorizer_algorithm.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.032664600Z",
     "start_time": "2024-04-20T00:45:21.006484800Z"
    }
   },
   "id": "68829c8e79c832d6",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# best_params = pipeline[1].best_params_\n",
    "# best_params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.073093200Z",
     "start_time": "2024-04-20T00:45:21.011924400Z"
    }
   },
   "id": "a52f7daa3601cbec",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# calibrated_pipeline = Pipeline(steps = [\n",
    "#     ('preprocessing', Preprocessing(features)),\n",
    "#     ('classifier', SVC(**best_params))\n",
    "# ])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.076927800Z",
     "start_time": "2024-04-20T00:45:21.018169900Z"
    }
   },
   "id": "1d4c2b914353900f",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pred = pd.DataFrame({'Review': ['bonito']})\n",
    "# pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.091939100Z",
     "start_time": "2024-04-20T00:45:21.023154300Z"
    }
   },
   "id": "3afab0d8441c0019",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # aún funciona, pero no sabemos si deberíamos usar todo el dataset\n",
    "# #df_sampled = custom_sampling(df, objective_distribution)\n",
    "# df_sampled = df.sample(frac=0.05)\n",
    "# df_pp = training_preprocessing(df_sampled)\n",
    "# # \n",
    "# xtr, xts, ytr, yts = separate_data(df_pp, 0.20)\n",
    "# calibrated_pipeline.fit(xtr, xts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.110420300Z",
     "start_time": "2024-04-20T00:45:21.027474800Z"
    }
   },
   "id": "d58429d9030ad812",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# calibrated_pipeline.predict(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.112420700Z",
     "start_time": "2024-04-20T00:45:21.034665300Z"
    }
   },
   "id": "2b5181b74874559c",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pipeline[0].feature_vectorizer_algorithm.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.126559200Z",
     "start_time": "2024-04-20T00:45:21.043725300Z"
    }
   },
   "id": "521cb66c6d1f2106",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# pipeline[0].feature_vectorizer_algorithm.vocabulary_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.128558200Z",
     "start_time": "2024-04-20T00:45:21.049404200Z"
    }
   },
   "id": "f03cf9bbad898db6",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:21.130692900Z",
     "start_time": "2024-04-20T00:45:21.053505Z"
    }
   },
   "id": "33276ade044036d2",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:45:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0ec1b1aec6d47179df26f48e91234bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 19:45:21 INFO: Downloaded file to C:\\Users\\alvar\\stanza_resources\\resources.json\n",
      "2024-04-19 19:45:21 INFO: Loading these models for language: es (Spanish):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | ancora          |\n",
      "| mwt       | ancora          |\n",
      "| pos       | ancora_charlm   |\n",
      "| lemma     | ancora_nocharlm |\n",
      "===============================\n",
      "\n",
      "2024-04-19 19:45:21 INFO: Using device: cpu\n",
      "2024-04-19 19:45:21 INFO: Loading: tokenize\n",
      "2024-04-19 19:45:21 INFO: Loading: mwt\n",
      "2024-04-19 19:45:21 INFO: Loading: pos\n",
      "2024-04-19 19:45:22 INFO: Loading: lemma\n",
      "2024-04-19 19:45:22 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "svc_param_grid={\n",
    "    'C': [0.1, 1, 10, 100],  # Parámetro de regularización\n",
    "    'kernel': ['linear', 'rbf'],  # Linear y RBF son los kernels más comunes\n",
    "}\n",
    "\n",
    "train_pipe = Pipeline(steps = [\n",
    "    ('lemmatize', Process()),\n",
    "    ('vectorize', TfidfVectorizer(\n",
    "        decode_error='ignore',\n",
    "        strip_accents='ascii',\n",
    "        analyzer='word',\n",
    "        max_features=10000\n",
    "    )),\n",
    "    ('classifier', GridSearchCV(SVC(), param_grid=svc_param_grid, cv=5, scoring='accuracy', n_jobs=None, verbose=2))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:22.314941100Z",
     "start_time": "2024-04-20T00:45:21.059738100Z"
    }
   },
   "id": "689cc3b931bdc817",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null elimination... OK (394, 2)\n",
      "Duplicate elimination... OK (394, 2)\n",
      "Ayptical length elimination... OK (348, 2)\n",
      "X train set: (278, 1)\n",
      "X test  set: (70, 1)\n",
      "Y train set: (278,)\n",
      "Y test  set: (70,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/tipo2_entrenamiento_estudiantes.csv', sep=',', encoding = 'utf-8')\n",
    "df_sampled = df.sample(frac=0.05)\n",
    "df_pp = training_preprocessing(df_sampled)\n",
    "xtr, xts, ytr, yts = separate_data(df_pp, 0.20)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:22.378421Z",
     "start_time": "2024-04-20T00:45:22.313939800Z"
    }
   },
   "id": "8b2b200dd956100c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "pandas.core.frame.DataFrame"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:45:22.382579900Z",
     "start_time": "2024-04-20T00:45:22.377410700Z"
    }
   },
   "id": "3179c09abf97fcb3",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza preprocessing... OK (278, 1)\n",
      "Additional cleaning... OK (278, 1)\n"
     ]
    }
   ],
   "source": [
    "res = train_pipe[0].transform(xtr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:47:01.237996800Z",
     "start_time": "2024-04-20T00:45:22.383589800Z"
    }
   },
   "id": "8887c15ac2cee09c",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 Review\n801                [5, principal, plaza, habana, vieja]\n4050  [excelente, servicio, francisco, garcia, rapid...\n2762  [ser, primero, vez, hospedir, hotel, ibi, pens...\n6720  [buen, tarde, alojar, hotel, hacer, 6, año, e...\n4365                                 [deteriorar, zona]\n3707  [excelente, servicio, comida, exquisito, super...\n2087  [recomendar, lugar, siempre, lleno, él, hacer...\n5088  [ser, corazon, caminito, sumergido, cultura, a...\n6680  [más, 100, bar, caribe, cuba, bahamas, miami,...\n7854                                        [defraudar]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>801</th>\n      <td>[5, principal, plaza, habana, vieja]</td>\n    </tr>\n    <tr>\n      <th>4050</th>\n      <td>[excelente, servicio, francisco, garcia, rapid...</td>\n    </tr>\n    <tr>\n      <th>2762</th>\n      <td>[ser, primero, vez, hospedir, hotel, ibi, pens...</td>\n    </tr>\n    <tr>\n      <th>6720</th>\n      <td>[buen, tarde, alojar, hotel, hacer, 6, año, e...</td>\n    </tr>\n    <tr>\n      <th>4365</th>\n      <td>[deteriorar, zona]</td>\n    </tr>\n    <tr>\n      <th>3707</th>\n      <td>[excelente, servicio, comida, exquisito, super...</td>\n    </tr>\n    <tr>\n      <th>2087</th>\n      <td>[recomendar, lugar, siempre, lleno, él, hacer...</td>\n    </tr>\n    <tr>\n      <th>5088</th>\n      <td>[ser, corazon, caminito, sumergido, cultura, a...</td>\n    </tr>\n    <tr>\n      <th>6680</th>\n      <td>[más, 100, bar, caribe, cuba, bahamas, miami,...</td>\n    </tr>\n    <tr>\n      <th>7854</th>\n      <td>[defraudar]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:47:01.266934400Z",
     "start_time": "2024-04-20T00:47:01.237996800Z"
    }
   },
   "id": "9c762b74a5c29b8c",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(278, 1)"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:47:01.269934400Z",
     "start_time": "2024-04-20T00:47:01.261112Z"
    }
   },
   "id": "443ed05e27cb3aa9",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'5 principal plaza habana vieja'"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "\n",
    "data_stringfied = copy(res)\n",
    "data_stringfied['Review'] = data_stringfied['Review'].apply(lambda x: ' '.join(map(str, x)))\n",
    "data_stringfied['Review'][801]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:54:15.918504800Z",
     "start_time": "2024-04-20T00:54:15.909677600Z"
    }
   },
   "id": "1771ea08a0f023c5",
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TfidfVectorizer(decode_error='ignore', max_features=10000,\n                strip_accents='ascii')",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(decode_error=&#x27;ignore&#x27;, max_features=10000,\n                strip_accents=&#x27;ascii&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;TfidfVectorizer<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>TfidfVectorizer(decode_error=&#x27;ignore&#x27;, max_features=10000,\n                strip_accents=&#x27;ascii&#x27;)</pre></div> </div></div></div></div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipe[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:47:01.306491100Z",
     "start_time": "2024-04-20T00:47:01.275447Z"
    }
   },
   "id": "bd7538277395f228",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<278x1229 sparse matrix of type '<class 'numpy.float64'>'\n\twith 3126 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = train_pipe[1].fit_transform(data_stringfied['Review'])\n",
    "res2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:56:41.359189700Z",
     "start_time": "2024-04-20T00:56:41.340403200Z"
    }
   },
   "id": "39e5e31c297ed9c1",
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['10', '100', '11', ..., 'yumka', 'zapato', 'zona'], dtype=object)"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipe[1].get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:56:46.824821600Z",
     "start_time": "2024-04-20T00:56:46.815547100Z"
    }
   },
   "id": "a12430e6d7d31fd2",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     0     1     2     3     4     5     6     7     8     9     ...  1219  \\\n0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n273   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n274   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n275   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n276   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n277   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n\n     1220  1221  1222  1223  1224  1225  1226  1227      1228  \n0     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n1     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n2     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n3     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n4     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.580497  \n..    ...   ...   ...   ...   ...   ...   ...   ...       ...  \n273   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n274   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n275   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n276   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n277   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000  \n\n[278 rows x 1229 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1219</th>\n      <th>1220</th>\n      <th>1221</th>\n      <th>1222</th>\n      <th>1223</th>\n      <th>1224</th>\n      <th>1225</th>\n      <th>1226</th>\n      <th>1227</th>\n      <th>1228</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.580497</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>273</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>278 rows × 1229 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2_df = pd.DataFrame(res2.toarray())\n",
    "res2_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:56:54.890541700Z",
     "start_time": "2024-04-20T00:56:54.863421300Z"
    }
   },
   "id": "f62970949704cd72",
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5, estimator=SVC(),\n             param_grid={'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']},\n             scoring='accuracy', verbose=2)",
      "text/html": "<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>GridSearchCV(cv=5, estimator=SVC(),\n             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100], &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">estimator: SVC</label><div class=\"sk-toggleable__content \"><pre>SVC()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;SVC<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></label><div class=\"sk-toggleable__content \"><pre>SVC()</pre></div> </div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipe[2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:57:26.341581900Z",
     "start_time": "2024-04-20T00:57:26.337904900Z"
    }
   },
   "id": "1652e47f131aa7d9",
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=0.1, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=0.1, kernel=rbf; total time=   0.0s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END .................................C=1, kernel=linear; total time=   0.0s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ....................................C=1, kernel=rbf; total time=   0.0s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ................................C=10, kernel=linear; total time=   0.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................................C=10, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...............................C=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............................C=100, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................................C=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=100, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................................C=100, kernel=rbf; total time=   0.0s\n"
     ]
    }
   ],
   "source": [
    "res3 = train_pipe[2].fit(res2, ytr)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T00:58:17.758533500Z",
     "start_time": "2024-04-20T00:58:17.318762300Z"
    }
   },
   "id": "e83b577ee237bf2d",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SVC(C=1)",
      "text/html": "<style>#sk-container-id-4 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-4 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-4 pre {\n  padding: 0;\n}\n\n#sk-container-id-4 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-4 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-4 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-4 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-4 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-4 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-4 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-4 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-4 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-4 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-4 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-4 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n#sk-container-id-4 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-4 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-4 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-4 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-4 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-4 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-4 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-4 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>SVC(C=1)</pre></div> </div></div></div></div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(**res3.best_params_)\n",
    "svc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T01:01:05.563967800Z",
     "start_time": "2024-04-20T01:01:05.553577700Z"
    }
   },
   "id": "4adff689e0d2e100",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 Review\n801                [5, principal, plaza, habana, vieja]\n4050  [excelente, servicio, francisco, garcia, rapid...\n2762  [ser, primero, vez, hospedir, hotel, ibi, pens...\n6720  [buen, tarde, alojar, hotel, hacer, 6, año, e...\n4365                                 [deteriorar, zona]\n...                                                 ...\n6005  [hotel, ser, maravilla, atención, primero, lu...\n1879  [visitar, dos, vez, catedral, sal, regresar, h...\n1597  [comida, debajo, espectativa, relación, calid...\n6261  [ser, castillo, bonito, recorrer, tú, ir, sug...\n1775  [acudir, lugar, recomendación, gente, mérida...\n\n[278 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>801</th>\n      <td>[5, principal, plaza, habana, vieja]</td>\n    </tr>\n    <tr>\n      <th>4050</th>\n      <td>[excelente, servicio, francisco, garcia, rapid...</td>\n    </tr>\n    <tr>\n      <th>2762</th>\n      <td>[ser, primero, vez, hospedir, hotel, ibi, pens...</td>\n    </tr>\n    <tr>\n      <th>6720</th>\n      <td>[buen, tarde, alojar, hotel, hacer, 6, año, e...</td>\n    </tr>\n    <tr>\n      <th>4365</th>\n      <td>[deteriorar, zona]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6005</th>\n      <td>[hotel, ser, maravilla, atención, primero, lu...</td>\n    </tr>\n    <tr>\n      <th>1879</th>\n      <td>[visitar, dos, vez, catedral, sal, regresar, h...</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>[comida, debajo, espectativa, relación, calid...</td>\n    </tr>\n    <tr>\n      <th>6261</th>\n      <td>[ser, castillo, bonito, recorrer, tú, ir, sug...</td>\n    </tr>\n    <tr>\n      <th>1775</th>\n      <td>[acudir, lugar, recomendación, gente, mérida...</td>\n    </tr>\n  </tbody>\n</table>\n<p>278 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(res2, ytr)\n",
    "xtr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T01:13:06.517009700Z",
     "start_time": "2024-04-20T01:13:06.496950700Z"
    }
   },
   "id": "f898653d1dd6d009",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stanza preprocessing... "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If neither 'pretokenized' or 'no_ssplit' option is enabled, the input to the TokenizerProcessor must be a string or a Document object.  Got <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[86], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m r1 \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_pipe\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m r1\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    293\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 295\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    297\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    298\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    299\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    300\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    301\u001B[0m         )\n",
      "Cell \u001B[1;32mIn[18], line 126\u001B[0m, in \u001B[0;36mProcess.transform\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtransform\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):        \n\u001B[0;32m    124\u001B[0m     \u001B[38;5;66;03m# tokenización + lematización Stanza\u001B[39;00m\n\u001B[0;32m    125\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStanza preprocessing... \u001B[39m\u001B[38;5;124m\"\u001B[39m, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 126\u001B[0m     X[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mReview\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mReview\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstanza_preprocessing\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOK\u001B[39m\u001B[38;5;124m\"\u001B[39m, X\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;66;03m# limpieza\u001B[39;00m\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\pandas\\core\\series.py:4915\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001B[0m\n\u001B[0;32m   4780\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4781\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4782\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4787\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4788\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4789\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4790\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4791\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4906\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4907\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   4908\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4909\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4910\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4911\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4912\u001B[0m \u001B[43m        \u001B[49m\u001B[43mby_row\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby_row\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4913\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4914\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m-> 4915\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_compat()\n\u001B[0;32m   1426\u001B[0m \u001B[38;5;66;03m# self.func is Callable\u001B[39;00m\n\u001B[1;32m-> 1427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;66;03m# row-wise access\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \u001B[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001B[39;00m\n\u001B[0;32m   1504\u001B[0m \u001B[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001B[39;00m\n\u001B[0;32m   1505\u001B[0m \u001B[38;5;66;03m#  Categorical (GH51645).\u001B[39;00m\n\u001B[0;32m   1506\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj\u001B[38;5;241m.\u001B[39mdtype, CategoricalDtype) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1507\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_values\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmapper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcurried\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1512\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1513\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\pandas\\core\\base.py:921\u001B[0m, in \u001B[0;36mIndexOpsMixin._map_values\u001B[1;34m(self, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, ExtensionArray):\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mmap(mapper, na_action\u001B[38;5;241m=\u001B[39mna_action)\n\u001B[1;32m--> 921\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43malgorithms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mna_action\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_action\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001B[0m, in \u001B[0;36mmap_array\u001B[1;34m(arr, mapper, na_action, convert)\u001B[0m\n\u001B[0;32m   1741\u001B[0m values \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m na_action \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1743\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1745\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mmap_infer_mask(\n\u001B[0;32m   1746\u001B[0m         values, mapper, mask\u001B[38;5;241m=\u001B[39misna(values)\u001B[38;5;241m.\u001B[39mview(np\u001B[38;5;241m.\u001B[39muint8), convert\u001B[38;5;241m=\u001B[39mconvert\n\u001B[0;32m   1747\u001B[0m     )\n",
      "File \u001B[1;32mlib.pyx:2972\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[18], line 23\u001B[0m, in \u001B[0;36mProcess.stanza_preprocessing\u001B[1;34m(self, words)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstanza_preprocessing\u001B[39m(\u001B[38;5;28mself\u001B[39m, words):\n\u001B[0;32m     14\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m    Uses the Stanza Pipeline to preprocess text\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m    Recommended before cleaning as stopword eliminations, lower-casing\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;124;03m    :return: (list) lemmas obtained\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 23\u001B[0m     doc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstanza_pipeline\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m     lemmas \u001B[38;5;241m=\u001B[39m [w\u001B[38;5;241m.\u001B[39mlemma \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m doc\u001B[38;5;241m.\u001B[39msentences[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mwords]\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m lemmas\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\stanza\\pipeline\\core.py:477\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, doc, processors)\u001B[0m\n\u001B[0;32m    476\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, doc, processors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m--> 477\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocessors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\stanza\\pipeline\\core.py:428\u001B[0m, in \u001B[0;36mPipeline.process\u001B[1;34m(self, doc, processors)\u001B[0m\n\u001B[0;32m    426\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors\u001B[38;5;241m.\u001B[39mget(processor_name):\n\u001B[0;32m    427\u001B[0m         process \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors[processor_name]\u001B[38;5;241m.\u001B[39mbulk_process \u001B[38;5;28;01mif\u001B[39;00m bulk \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocessors[processor_name]\u001B[38;5;241m.\u001B[39mprocess\n\u001B[1;32m--> 428\u001B[0m         doc \u001B[38;5;241m=\u001B[39m \u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    429\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m doc\n",
      "File \u001B[1;32m~\\prog\\bi\\ISIS-3301-P1-G32\\env\\Lib\\site-packages\\stanza\\pipeline\\tokenize_processor.py:82\u001B[0m, in \u001B[0;36mTokenizeProcessor.process\u001B[1;34m(self, document)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, document):\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(document, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(document, doc\u001B[38;5;241m.\u001B[39mDocument) \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpretokenized\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mno_ssplit\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m))):\n\u001B[1;32m---> 82\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf neither \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpretokenized\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mno_ssplit\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m option is enabled, the input to the TokenizerProcessor must be a string or a Document object.  Got \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mtype\u001B[39m(document)))\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(document, doc\u001B[38;5;241m.\u001B[39mDocument):\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpretokenized\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[1;31mValueError\u001B[0m: If neither 'pretokenized' or 'no_ssplit' option is enabled, the input to the TokenizerProcessor must be a string or a Document object.  Got <class 'list'>"
     ]
    }
   ],
   "source": [
    "r1 = train_pipe[0].transform(xts)\n",
    "r1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-20T01:13:53.041570Z",
     "start_time": "2024-04-20T01:13:52.938403900Z"
    }
   },
   "id": "cbb636fd3dd39ab0",
   "execution_count": 86
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
